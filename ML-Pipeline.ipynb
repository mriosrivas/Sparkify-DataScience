{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8dedc39",
   "metadata": {},
   "source": [
    "# ML Pipeline\n",
    "\n",
    "This Jupyter Notebook demonstrates the implementation of a pipeline using PySpark. The pipeline includes data preprocessing, feature engineering, and model training. In addition, we perform cross-validation to find the best model and save it for future use. The dataset used in this notebook is a dataset on customer churn.\n",
    "Data Loading\n",
    "\n",
    "The first step in this process is to load the customer churn dataset. The dataset should be loaded into a PySpark DataFrame.\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "After preprocessing, we perform feature engineering to create new features that may be useful in predicting customer churn. In this notebook, we use PySpark's VectorAssembler to combine all the features into a single vector.\n",
    "\n",
    "## Model Training\n",
    "\n",
    "With the data prepared and engineered, the next step is to train the models. We use PySpark's Pipeline class to define a pipeline that includes the preprocessing, feature engineering, and model training steps. We train three different classifiers - logistic regression, random forest, and naive Bayes classifier. We also perform cross-validation to determine the best model.\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "After training the models, we evaluate their performance using metrics such as accuracy, precision, recall, and F1-score. In this case we use the ROC value. We also calculate the confusion matrix for each model.\n",
    "\n",
    "## Model Selection and Saving\n",
    "\n",
    "Based on the evaluation results, we select the best model, which turns out to be the random forest classifier. We save this model for future use.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this Jupyter Notebook, we have demonstrated the implementation of a pipeline using PySpark for customer churn prediction. We performed data preprocessing, feature engineering, and model training using PySpark's built-in libraries. We also performed cross-validation to find the best model and saved it for future use. The random forest classifier was found to be the best model based on evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16fbcca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, udf\n",
    "from pyspark.sql.functions import max as fmax, min as fmin\n",
    "from pyspark.sql.types import IntegerType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b67abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, NaiveBayes\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f970488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CurveMetrics import CurveMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfd8477a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/11 11:12:32 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.248.232 instead (on interface wlp110s0)\n",
      "23/03/11 11:12:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/11 11:12:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3236272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d48b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in full sparkify dataset\n",
    "# Full dataset\n",
    "# event_data = \"s3n://udacity-dsnd/sparkify/sparkify_event_data.json\"\n",
    "event_data = \"clean_data/part-00000-e576dd1f-cbc4-437f-abcd-f83e8d8519fa-c000.csv\"\n",
    "# Mini dataset\n",
    "#event_data = \"mini_sparkify_event_data.json\"\n",
    "df = spark.read.csv(event_data, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14138d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['n_pages', \n",
    "            'thumbs_down', \n",
    "            'home', \n",
    "            'downgrade', \n",
    "            'roll_advert', \n",
    "            'about', \n",
    "            'add_playlist', \n",
    "            'nextsong', \n",
    "            'thumbs_up', \n",
    "            'error', \n",
    "            'submit_upgrade', \n",
    "            'total_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2baa11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast data to integers\n",
    "for i in range(len(features)):\n",
    "    df = df.withColumn(features[i] , df[features[i]].cast(IntegerType()))\n",
    "    \n",
    "df = df.withColumn('label' , df['label'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efe80c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- n_pages: integer (nullable = true)\n",
      " |-- thumbs_down: integer (nullable = true)\n",
      " |-- home: integer (nullable = true)\n",
      " |-- downgrade: integer (nullable = true)\n",
      " |-- roll_advert: integer (nullable = true)\n",
      " |-- about: integer (nullable = true)\n",
      " |-- add_playlist: integer (nullable = true)\n",
      " |-- nextsong: integer (nullable = true)\n",
      " |-- thumbs_up: integer (nullable = true)\n",
      " |-- error: integer (nullable = true)\n",
      " |-- submit_upgrade: integer (nullable = true)\n",
      " |-- total_length: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67506d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test data\n",
    "train, test = df.randomSplit([0.9, 0.1], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c90a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "lr = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "nb = NaiveBayes()\n",
    "\n",
    "\n",
    "lrPipeline = Pipeline(stages=[assembler, lr])\n",
    "rfPipeline = Pipeline(stages=[assembler, rf])\n",
    "nbPipeline = Pipeline(stages=[assembler, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c2feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model tuning\n",
    "lrParamGrid = ParamGridBuilder()\\\n",
    "            .addGrid(lr.regParam, [0.0, 0.1, 1.0])\\\n",
    "            .addGrid(lr.maxIter, [100])\\\n",
    "            .build()\n",
    "\n",
    "rfParamGrid = ParamGridBuilder()\\\n",
    "            .addGrid(rf.numTrees, [3, 5, 10])\\\n",
    "            .addGrid(rf.maxDepth, [2, 5, 10, 20])\\\n",
    "            .build()\n",
    "\n",
    "nbParamGrid = ParamGridBuilder()\\\n",
    "            .addGrid(nb.modelType, ['multinomial', 'gaussian'])\\\n",
    "            .build()\n",
    "\n",
    "lrCrossval = CrossValidator(estimator = lrPipeline,\n",
    "                         estimatorParamMaps = lrParamGrid,\n",
    "                         evaluator = BinaryClassificationEvaluator(metricName='areaUnderROC'),\n",
    "                         numFolds = 3)\n",
    "\n",
    "rfCrossval = CrossValidator(estimator = rfPipeline,\n",
    "                         estimatorParamMaps = rfParamGrid,\n",
    "                         evaluator = BinaryClassificationEvaluator(metricName='areaUnderROC'),\n",
    "                         numFolds = 3)\n",
    "\n",
    "nbCrossval = CrossValidator(estimator = nbPipeline,\n",
    "                         estimatorParamMaps = nbParamGrid,\n",
    "                         evaluator = BinaryClassificationEvaluator(metricName='areaUnderROC'),\n",
    "                         numFolds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffdda74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lrCVModel = lrCrossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7da747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/11 11:13:13 WARN DAGScheduler: Broadcasting large task binary with size 1065.7 KiB\n",
      "23/03/11 11:13:13 WARN DAGScheduler: Broadcasting large task binary with size 1155.0 KiB\n",
      "23/03/11 11:13:14 WARN DAGScheduler: Broadcasting large task binary with size 1232.8 KiB\n",
      "23/03/11 11:13:19 WARN DAGScheduler: Broadcasting large task binary with size 1195.9 KiB\n",
      "23/03/11 11:13:19 WARN DAGScheduler: Broadcasting large task binary with size 1447.6 KiB\n",
      "23/03/11 11:13:19 WARN DAGScheduler: Broadcasting large task binary with size 1698.2 KiB\n",
      "23/03/11 11:13:20 WARN DAGScheduler: Broadcasting large task binary with size 1936.2 KiB\n",
      "23/03/11 11:13:20 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "23/03/11 11:13:20 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/03/11 11:13:20 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/03/11 11:13:21 WARN DAGScheduler: Broadcasting large task binary with size 1560.6 KiB\n",
      "23/03/11 11:13:30 WARN DAGScheduler: Broadcasting large task binary with size 1056.9 KiB\n",
      "23/03/11 11:13:30 WARN DAGScheduler: Broadcasting large task binary with size 1157.4 KiB\n",
      "23/03/11 11:13:30 WARN DAGScheduler: Broadcasting large task binary with size 1244.0 KiB\n",
      "23/03/11 11:13:30 WARN DAGScheduler: Broadcasting large task binary with size 1313.0 KiB\n",
      "23/03/11 11:13:35 WARN DAGScheduler: Broadcasting large task binary with size 1218.9 KiB\n",
      "23/03/11 11:13:35 WARN DAGScheduler: Broadcasting large task binary with size 1483.1 KiB\n",
      "23/03/11 11:13:36 WARN DAGScheduler: Broadcasting large task binary with size 1738.5 KiB\n",
      "23/03/11 11:13:36 WARN DAGScheduler: Broadcasting large task binary with size 1965.1 KiB\n",
      "23/03/11 11:13:36 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "23/03/11 11:13:37 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/03/11 11:13:37 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/03/11 11:13:37 WARN DAGScheduler: Broadcasting large task binary with size 1537.5 KiB\n",
      "23/03/11 11:13:45 WARN DAGScheduler: Broadcasting large task binary with size 1046.7 KiB\n",
      "23/03/11 11:13:46 WARN DAGScheduler: Broadcasting large task binary with size 1144.5 KiB\n",
      "23/03/11 11:13:46 WARN DAGScheduler: Broadcasting large task binary with size 1226.7 KiB\n",
      "23/03/11 11:13:46 WARN DAGScheduler: Broadcasting large task binary with size 1289.6 KiB\n",
      "23/03/11 11:13:51 WARN DAGScheduler: Broadcasting large task binary with size 1172.5 KiB\n",
      "23/03/11 11:13:51 WARN DAGScheduler: Broadcasting large task binary with size 1411.6 KiB\n",
      "23/03/11 11:13:51 WARN DAGScheduler: Broadcasting large task binary with size 1647.5 KiB\n",
      "23/03/11 11:13:51 WARN DAGScheduler: Broadcasting large task binary with size 1876.5 KiB\n",
      "23/03/11 11:13:52 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/03/11 11:13:52 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/03/11 11:13:52 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/03/11 11:13:53 WARN DAGScheduler: Broadcasting large task binary with size 1532.4 KiB\n"
     ]
    }
   ],
   "source": [
    "rfCVModel = rfCrossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "499d57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbCVModel =nbCrossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd33b8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "-----------------------------------------------------\n",
      "AUC = [0.8802065948551241, 0.8683154764361208, 0.8388433362530979]\n",
      "\n",
      "Best model parameters:\n",
      "maxIter = 100\n",
      "regParam = 0.0\n",
      "\n",
      "\n",
      "Random Forest Results:\n",
      "-----------------------------------------------------\n",
      "AUC = [0.8296629598306268, 0.9082539268220223, 0.9279110497721451, 0.8891194375043273, 0.8284132315305666, 0.9241678996471556, 0.9334208356537799, 0.9059189986523511, 0.874269895030889, 0.9221956445575673, 0.9370659010059413, 0.923195084657712]\n",
      "\n",
      "Best model parameters:\n",
      "numTrees = 10\n",
      "maxDepth = 10\n",
      "\n",
      "\n",
      "Naive Bayes Results:\n",
      "-----------------------------------------------------\n",
      "AUC = [0.21472747290453742, 0.6384957955855403]\n",
      "\n",
      "Best model parameters:\n",
      "modelType = gaussian\n"
     ]
    }
   ],
   "source": [
    "lr_dict = {'avgMetrics': lrCVModel.avgMetrics,\n",
    "          'maxIter' : lrCVModel.bestModel.stages[1]._java_obj.getMaxIter(),\n",
    "          'regParam' : lrCVModel.bestModel.stages[1]._java_obj.getRegParam()}\n",
    "\n",
    "rf_dict = {'avgMetrics' : rfCVModel.avgMetrics,\n",
    "           'numTrees' : rfCVModel.bestModel.stages[1]._java_obj.getNumTrees(),\n",
    "           'maxDepth' : rfCVModel.bestModel.stages[1]._java_obj.getMaxDepth()}\n",
    "\n",
    "nb_dict = {'avgMetrics' : nbCVModel.avgMetrics,\n",
    "        'modelType' : nbCVModel.bestModel.stages[1]._java_obj.getModelType()}\n",
    "\n",
    "\n",
    "print('Logistic Regression Results:')\n",
    "print('-----------------------------------------------------')\n",
    "print(f'AUC = {lr_dict[\"avgMetrics\"]}')\n",
    "print('\\nBest model parameters:')\n",
    "print(f'maxIter = {lr_dict[\"maxIter\"]}')\n",
    "print(f'regParam = {lr_dict[\"regParam\"]}')\n",
    "\n",
    "print('\\n\\nRandom Forest Results:')\n",
    "print('-----------------------------------------------------')\n",
    "print(f'AUC = {rf_dict[\"avgMetrics\"]}')\n",
    "print('\\nBest model parameters:')\n",
    "print(f'numTrees = {rf_dict[\"numTrees\"]}')\n",
    "print(f'maxDepth = {rf_dict[\"maxDepth\"]}')\n",
    "\n",
    "print('\\n\\nNaive Bayes Results:')\n",
    "print('-----------------------------------------------------')\n",
    "print(f'AUC = {nb_dict[\"avgMetrics\"]}')\n",
    "print('\\nBest model parameters:')\n",
    "print(f'modelType = {nb_dict[\"modelType\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d94b754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lrModel = lrCVModel.bestModel\n",
    "\n",
    "# Random Forest\n",
    "rfModel = rfCVModel.bestModel\n",
    "\n",
    "# Naive Bayes\n",
    "nbModel = nbCVModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e727d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred_lr = lrModel.transform(test)\n",
    "pred_rf = rfModel.transform(test)\n",
    "pred_nb = nbModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e4aa08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "def get_confusion_matrix(pred):\n",
    "    #important: need to cast to float type, and order by prediction, else it won't work\n",
    "    preds_and_labels = pred.select(['prediction','label'])\\\n",
    "                        .withColumn('label', col('label').cast(FloatType()))\\\n",
    "                        .orderBy('prediction')\n",
    "\n",
    "    #select only prediction and label columns\n",
    "    preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "\n",
    "    metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def get_metrics(metrics):\n",
    "    tn, fp, fn, tp = metrics.confusionMatrix().toArray().ravel().astype('int')\n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "    f1 = 2/(1/p + 1/r)\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5dea971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/anaconda3/envs/data-analysis/lib/python3.8/site-packages/pyspark/sql/context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "metrics_lr = get_confusion_matrix(pred_lr)\n",
    "metrics_rf = get_confusion_matrix(pred_rf)\n",
    "metrics_nb = get_confusion_matrix(pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae5f6163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[1648   48]\n",
      " [ 251  274]]\n",
      "\n",
      " Random Forest\n",
      "[[1681   15]\n",
      " [ 231  294]]\n",
      "\n",
      " Naive Bayes\n",
      "[[1532  164]\n",
      " [ 314  211]]\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression')\n",
    "print(metrics_lr.confusionMatrix().toArray().astype('int'))\n",
    "\n",
    "print('\\n Random Forest')\n",
    "print(metrics_rf.confusionMatrix().toArray().astype('int'))\n",
    "\n",
    "print('\\n Naive Bayes')\n",
    "print(metrics_nb.confusionMatrix().toArray().astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a766e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(np.array([get_metrics(metrics_lr), \n",
    "                                 get_metrics(metrics_rf),\n",
    "                                 get_metrics(metrics_nb)]),\n",
    "                       columns=['precision', 'recall', 'f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3e2696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['model'] = ['logistic regression', 'random forest', 'naive bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c54416b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.850932</td>\n",
       "      <td>0.521905</td>\n",
       "      <td>0.646989</td>\n",
       "      <td>logistic regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.951456</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.705036</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.401905</td>\n",
       "      <td>0.468889</td>\n",
       "      <td>naive bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score                model\n",
       "0   0.850932  0.521905  0.646989  logistic regression\n",
       "1   0.951456  0.560000  0.705036        random forest\n",
       "2   0.562667  0.401905  0.468889          naive bayes"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27a357fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1955:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "rfModel.save('model/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
